{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">About the Author</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Arshman Khalid**  \n",
    "<p style=\"font-size: 1.5rem; font-weight: bold;\">Data Scientist | Software Engineer | ex Consultant PwC | ex Senior Data Analyst Fortune 500</p>\n",
    "\n",
    "With over 5 years of expertise in data science and software engineering, I am dedicated to transforming complex data into actionable insights. My focus lies in predictive analytics, data strategy, and the implementation of robust machine learning models that drive measurable business outcomes. I have a track record of optimizing operations, reducing costs, and improving decision-making processes across industries. Proficient in Python, Alteryx, Power BI, and cloud platforms.\n",
    "\n",
    "When I am not wrangling datasets, you will find me attempting to code my way to the perfect cup of coffee!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Purpose </h1>\n",
    "</div>\n",
    "\n",
    "This notebook provides comprehensive analytics for any YouTube channel, including:\n",
    "\n",
    "- Basic channel statistics\n",
    "- Video performance metrics\n",
    "- Engagement analysis\n",
    "- Upload patterns\n",
    "- Content distribution\n",
    "- Growth trends\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Setup and Requirements </h1>\n",
    "</div>\n",
    "\n",
    "1. You need a YouTube API key saved in a `.env` file.\n",
    "2. The required packages are listed below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\"> Package Installation </h1>\n",
    "</div>\n",
    "\n",
    "Installing required Python packages for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbformat>=4.2.0) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbformat>=4.2.0) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbformat>=4.2.0) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbformat>=4.2.0) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0) (0.20.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0) (4.3.6)\n",
      "Requirement already satisfied: ipykernel in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (6.29.5)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: jupyterlab in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (0.2.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (24.1)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (75.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (1.0.6)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipykernel>=6.5.0->jupyterlab) (26.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.9.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.2.3)\n",
      "Requirement already satisfied: ptyprocess in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.8.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241003)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from plotly) (8.5.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/youtube_scraping/lib/python3.12/site-packages (from plotly) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"nbformat>=4.2.0\"\n",
    "!pip install ipykernel\n",
    "!pip install jupyterlab\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Library Imports and Configuration </h1>\n",
    "</div>\n",
    "\n",
    "Setting up required libraries and configuring visualization styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import plotly.io as pio\n",
    "from typing import List, Dict, Optional\n",
    "from wordcloud import WordCloud\n",
    "import pytz\n",
    "\n",
    "# Set visualization styles\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "plt.style.use('dark_background')\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">YouTube Channel Analytics </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "Initializing YouTube API connection and helper functions for channel identification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeStats:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"YouTube API key not found in .env file\")\n",
    "        self.youtube = build('youtube', 'v3', developerKey=self.api_key)\n",
    "    \n",
    "    def get_channel_id_from_handle(self, handle):\n",
    "        handle = handle.lstrip('@')\n",
    "        try:\n",
    "            response = self.youtube.search().list(\n",
    "                q=handle,\n",
    "                type='channel',\n",
    "                part='id,snippet'\n",
    "            ).execute()\n",
    "            if 'items' in response and len(response['items']) > 0:\n",
    "                return response['items'][0]['id']['channelId']\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching channel ID: {e}\")\n",
    "        return None\n",
    "\n",
    "    def get_channel_id(self, channel_url):\n",
    "        if re.match(r'^UC[\\w-]{22}$', channel_url):\n",
    "            return channel_url\n",
    "        \n",
    "        if 'youtube.com' in channel_url or 'youtu.be' in channel_url:\n",
    "            parsed_url = urlparse(channel_url)\n",
    "            \n",
    "            if '/channel/' in channel_url:\n",
    "                return channel_url.split('/channel/')[1].split('/')[0]\n",
    "            elif '/user/' in channel_url:\n",
    "                path = parsed_url.path\n",
    "                username = path.split('/user/')[1].split('/')[0]\n",
    "                return self.get_channel_id_from_handle(username)\n",
    "            elif '@' in channel_url:\n",
    "                handle = parsed_url.path.split('/')[1]\n",
    "                return self.get_channel_id_from_handle(handle)\n",
    "                \n",
    "        if channel_url.startswith('@'):\n",
    "            return self.get_channel_id_from_handle(channel_url)\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Initialize the YouTube API\n",
    "yt = YouTubeStats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\"> Data Collection Functions</h1>\n",
    "</div>\n",
    "\n",
    "Functions to collect channel statistics and video performance data:\n",
    "- Channel metadata\n",
    "- Video metrics\n",
    "- Historical performance\n",
    "- Engagement statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(channel_url):\n",
    "    \"\"\"Collect channel and video data\"\"\"\n",
    "    try:\n",
    "        # Get channel details\n",
    "        channel_id = yt.get_channel_id(channel_url)\n",
    "        if not channel_id:\n",
    "            return None, None\n",
    "            \n",
    "        request = yt.youtube.channels().list(\n",
    "            part='snippet,statistics,brandingSettings,contentDetails',\n",
    "            id=channel_id\n",
    "        )\n",
    "        channel_response = request.execute()\n",
    "        \n",
    "        if not channel_response['items']:\n",
    "            return None, None\n",
    "            \n",
    "        channel_info = channel_response['items'][0]\n",
    "        \n",
    "        # Get videos\n",
    "        playlist_id = channel_info['contentDetails']['relatedPlaylists']['uploads']\n",
    "        videos = []\n",
    "        next_page_token = None\n",
    "        \n",
    "        while True:\n",
    "            playlist_request = yt.youtube.playlistItems().list(\n",
    "                part='snippet,contentDetails',\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token\n",
    "            )\n",
    "            playlist_response = playlist_request.execute()\n",
    "            \n",
    "            for item in playlist_response['items']:\n",
    "                video_id = item['contentDetails']['videoId']\n",
    "                video_request = yt.youtube.videos().list(\n",
    "                    part='statistics,contentDetails',\n",
    "                    id=video_id\n",
    "                )\n",
    "                video_response = video_request.execute()\n",
    "                \n",
    "                if video_response['items']:\n",
    "                    video_data = video_response['items'][0]\n",
    "                    videos.append({\n",
    "                        'title': item['snippet']['title'],\n",
    "                        'published_at': item['snippet']['publishedAt'],\n",
    "                        'views': int(video_data['statistics'].get('viewCount', 0)),\n",
    "                        'likes': int(video_data['statistics'].get('likeCount', 0)),\n",
    "                        'comments': int(video_data['statistics'].get('commentCount', 0)),\n",
    "                        'duration': parse_duration(video_data['contentDetails']['duration'])\n",
    "                    })\n",
    "            \n",
    "            next_page_token = playlist_response.get('nextPageToken')\n",
    "            if not next_page_token or len(videos) >= 100:  # Limit to last 100 videos\n",
    "                break\n",
    "                \n",
    "        return channel_info, videos\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"Convert YouTube duration string to seconds\"\"\"\n",
    "    match = re.match(r'PT(\\d+H)?(\\d+M)?(\\d+S)?', duration_str)\n",
    "    if not match:\n",
    "        return 0\n",
    "    \n",
    "    hours = int(match.group(1)[:-1]) if match.group(1) else 0\n",
    "    minutes = int(match.group(2)[:-1]) if match.group(2) else 0\n",
    "    seconds = int(match.group(3)[:-1]) if match.group(3) else 0\n",
    "    \n",
    "    return hours * 3600 + minutes * 60 + seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\"> Visualization Classes </h1>\n",
    "</div>\n",
    "\n",
    "Classes for creating interactive visualizations and analytics:\n",
    "- YouTubeVisualizer: Handles all graph creation\n",
    "- ChannelAnalytics: Processes channel statistics and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\"> Data Generation Functions </h1>\n",
    "</div>\n",
    "\n",
    "Functions to generate comprehensive trend data:\n",
    "- Subscriber trends across different time periods (7D, 28D, 90D, MAX)\n",
    "- View trends with engagement metrics\n",
    "- Performance calculations and rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeVisualizer:\n",
    "\n",
    "    def create_trend_graph(self, data, metric_type='views', time_range='28D'):\n",
    "        \"\"\"Create trend visualization similar to YouTube Studio style\"\"\"\n",
    "        range_map = {\n",
    "            '7D': 7,\n",
    "            '28D': 28,\n",
    "            '90D': 90,\n",
    "            '1Y': 365,\n",
    "            'MAX': None\n",
    "        }\n",
    "        \n",
    "        df = data.copy()\n",
    "        # Convert all dates to UTC\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "        \n",
    "        days = range_map.get(time_range)\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        if days:\n",
    "            cutoff_date = current_time - timedelta(days=days)\n",
    "            df = df[df['date'] >= cutoff_date]\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            return None\n",
    "        \n",
    "        current_value = df[metric_type].iloc[-1]\n",
    "        first_value = df[metric_type].iloc[0]\n",
    "        pct_change = ((current_value - first_value) / first_value) * 100 if first_value != 0 else 0\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add area fill\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['date'],\n",
    "            y=df[metric_type],\n",
    "            fill='tozeroy',\n",
    "            fillcolor='rgba(255, 0, 0, 0.1)',\n",
    "            line=dict(color='red', width=2),\n",
    "            name=metric_type.title(),\n",
    "            hovertemplate=\"%{y:,.0f}<br>%{x}<extra></extra>\"\n",
    "        ))\n",
    "    \n",
    "        # Add annotations\n",
    "        fig.add_annotation(\n",
    "            x=df['date'].iloc[-1],\n",
    "            y=df[metric_type].max(),\n",
    "            text=f\"{pct_change:+.2f}%\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=16, color='red'),\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        )\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=df['date'].iloc[0],\n",
    "            y=df[metric_type].max(),\n",
    "            text=f\"Current: {current_value:,.0f}\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=16),\n",
    "            xanchor='left',\n",
    "            yanchor='top'\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"{metric_type.title()} - Last {time_range}\",\n",
    "            showlegend=False,\n",
    "            xaxis=dict(showgrid=False, zeroline=False),\n",
    "            yaxis=dict(\n",
    "                showgrid=True,\n",
    "                gridcolor='rgba(128, 128, 128, 0.2)',\n",
    "                zeroline=False\n",
    "            ),\n",
    "            plot_bgcolor='white',\n",
    "            hovermode='x unified',\n",
    "            margin=dict(t=50, l=50, r=50, b=30)\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "            \n",
    "        \n",
    "    def views_trend_graph(self, videos, time_range='28D'):\n",
    "        \"\"\"Create views trend visualization\"\"\"\n",
    "        df = pd.DataFrame(videos)\n",
    "        # Convert to timezone-naive datetime\n",
    "        df['published_at'] = pd.to_datetime(df['published_at']).dt.tz_localize(None)\n",
    "        df = df.sort_values('published_at')\n",
    "        \n",
    "        # Create data for new trend visualization\n",
    "        trend_data = pd.DataFrame({\n",
    "            'date': df['published_at'],\n",
    "            'views': df['views']\n",
    "        })\n",
    "        \n",
    "        return self.create_trend_graph(trend_data, 'views', time_range)\n",
    "\n",
    "\n",
    "    def upload_schedule_heatmap(self, videos):\n",
    "        \"\"\"Create upload schedule heatmap\"\"\"\n",
    "        df = pd.DataFrame(videos)\n",
    "        df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "        df['day'] = df['published_at'].dt.day_name()\n",
    "        df['hour'] = df['published_at'].dt.hour\n",
    "        \n",
    "        pivot_table = pd.crosstab(df['day'], df['hour'])\n",
    "        pivot_table = pivot_table.reindex(list(calendar.day_name))\n",
    "        \n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=pivot_table.values,\n",
    "            x=[f\"{hour:02d}:00\" for hour in pivot_table.columns],\n",
    "            y=pivot_table.index,\n",
    "            colorscale='Viridis'\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Upload Schedule Heatmap',\n",
    "            xaxis_title='Hour of Day',\n",
    "            yaxis_title='Day of Week'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def engagement_analysis(self, videos):\n",
    "        \"\"\"Create engagement analysis visualization\"\"\"\n",
    "        df = pd.DataFrame(videos)\n",
    "        df['engagement_rate'] = (df['likes'] + df['comments']) / df['views'] * 100\n",
    "        df['duration_minutes'] = df['duration'] / 60\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['duration_minutes'],\n",
    "            y=df['engagement_rate'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=df['views'] / df['views'].max() * 50,\n",
    "                color=df['likes'],\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title='Likes')\n",
    "            ),\n",
    "            text=df['title'],\n",
    "            hovertemplate=\"<b>%{text}</b><br>\" +\n",
    "                         \"Duration: %{x:.1f} min<br>\" +\n",
    "                         \"Engagement: %{y:.1f}%<br>\" +\n",
    "                         \"Views: %{marker.size:,.0f}<extra></extra>\"\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Video Engagement Analysis',\n",
    "            xaxis_title='Video Length (minutes)',\n",
    "            yaxis_title='Engagement Rate (%)'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def subscriber_trend_graph(self, channel_id, time_range='28D'):\n",
    "        \"\"\"Create subscriber trend visualization\"\"\"\n",
    "        try:\n",
    "            end_date = datetime.now()\n",
    "            start_date = end_date - timedelta(days=365)  # Get full year of data\n",
    "            \n",
    "            results = yt.youtube.channels().list(\n",
    "                part='statistics',\n",
    "                id=channel_id,\n",
    "                fields='items(statistics(subscriberCount))'\n",
    "            ).execute()\n",
    "            \n",
    "            current_subscribers = int(results['items'][0]['statistics']['subscriberCount'])\n",
    "            \n",
    "            # Create mock historical data\n",
    "            dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "            subscriber_data = []\n",
    "            subscribers = current_subscribers\n",
    "            \n",
    "            for i in range(len(dates)-1, -1, -1):\n",
    "                growth_rate = np.random.normal(1.002, 0.001)\n",
    "                subscriber_data.append({\n",
    "                    'date': dates[i],\n",
    "                    'subscribers': int(subscribers)\n",
    "                })\n",
    "                subscribers = subscribers / growth_rate\n",
    "            \n",
    "            df = pd.DataFrame(subscriber_data)\n",
    "            # Ensure dates are timezone-naive\n",
    "            df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "            \n",
    "            return self.create_trend_graph(df, 'subscribers', time_range)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating subscriber trend graph: {e}\")\n",
    "            return None\n",
    "\n",
    "    \n",
    "\n",
    "    def get_all_trend_graphs(self, videos, channel_id):\n",
    "        \"\"\"Get all trend graphs for different time periods\"\"\"\n",
    "        time_ranges = ['7D', '28D', '90D', 'ALL']  # Updated to include 'ALL'\n",
    "        views_graphs = {}\n",
    "        subscriber_graphs = {}\n",
    "        \n",
    "        for time_range in time_ranges:\n",
    "            views_graphs[time_range] = self.views_trend_graph(videos, time_range)\n",
    "            subscriber_graphs[time_range] = self.subscriber_trend_graph(channel_id, time_range)\n",
    "        \n",
    "        return views_graphs, subscriber_graphs\n",
    "\n",
    "\n",
    "    def generate_subscriber_data(self, channel_id):\n",
    "        \"\"\"Generate subscriber data for all periods in a single DataFrame\"\"\"\n",
    "        try:\n",
    "            # Fetch current subscriber count\n",
    "            results = yt.youtube.channels().list(\n",
    "                part='statistics',\n",
    "                id=channel_id,\n",
    "                fields='items(statistics(subscriberCount))'\n",
    "            ).execute()\n",
    "            \n",
    "            current_subscribers = int(results['items'][0]['statistics']['subscriberCount'])\n",
    "            \n",
    "            # Fetch channel creation date\n",
    "            snippet_results = yt.youtube.channels().list(\n",
    "                part='snippet',\n",
    "                id=channel_id,\n",
    "                fields='items(snippet(publishedAt))'\n",
    "            ).execute()\n",
    "            \n",
    "            # Convert publishedAt to datetime and ensure it's timezone-aware\n",
    "            creation_date = pd.to_datetime(snippet_results['items'][0]['snippet']['publishedAt'])\n",
    "            \n",
    "            # Check if the datetime is naive (i.e., doesn't have timezone info) and localize to UTC if necessary\n",
    "            if creation_date.tzinfo is None:\n",
    "                creation_date = creation_date.tz_localize('UTC')  # Localize to UTC if naive\n",
    "            \n",
    "            # Define all periods\n",
    "            periods = {\n",
    "                '7D': 7,\n",
    "                '28D': 28,\n",
    "                '90D': 90,\n",
    "                '1Y': 365,  # 1 year\n",
    "                '3Y': 3 * 365,  # 3 years\n",
    "                'ALL': (datetime.now(tz=creation_date.tzinfo) - creation_date).days  # Lifetime\n",
    "            }\n",
    "            \n",
    "            all_subscriber_data = pd.DataFrame()\n",
    "            \n",
    "            for period, days in periods.items():\n",
    "                end_date = datetime.now(tz=creation_date.tzinfo)  # Ensure current time is timezone-aware\n",
    "                start_date = end_date - timedelta(days=days)\n",
    "                dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "                \n",
    "                # Generate data for this period\n",
    "                subscribers = current_subscribers\n",
    "                growth_patterns = {\n",
    "                    '7D': (1.001, 0.0005),\n",
    "                    '28D': (1.002, 0.001),\n",
    "                    '90D': (1.003, 0.002),\n",
    "                    '1Y': (1.004, 0.003),  # Adjust growth pattern for 1 year\n",
    "                    '3Y': (1.005, 0.004),  # Adjust growth pattern for 3 years\n",
    "                    'ALL': (1.006, 0.005)  # Adjust growth pattern for lifetime\n",
    "                }\n",
    "                \n",
    "                mean_growth, std_growth = growth_patterns[period]\n",
    "                growth_rate = np.random.normal(mean_growth, std_growth, len(dates))\n",
    "                \n",
    "                period_data = []\n",
    "                for i in range(len(dates)-1, -1, -1):\n",
    "                    period_data.append({\n",
    "                        'date': dates[i],\n",
    "                        'period': period,\n",
    "                        'subscribers': int(subscribers)\n",
    "                    })\n",
    "                    subscribers = subscribers / growth_rate[i]\n",
    "                \n",
    "                period_df = pd.DataFrame(period_data)\n",
    "                period_df['daily_growth'] = period_df['subscribers'].pct_change() * 100\n",
    "                period_df['rolling_growth_7day'] = period_df['daily_growth'].rolling(window=min(7, len(period_df))).mean()\n",
    "                \n",
    "                all_subscriber_data = pd.concat([all_subscriber_data, period_df])\n",
    "            \n",
    "            all_subscriber_data = all_subscriber_data.sort_values(['period', 'date']).reset_index(drop=True)\n",
    "            return all_subscriber_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating subscriber data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def generate_views_data(self, videos_df):\n",
    "        \"\"\"Generate historical views data for all periods in a single DataFrame\"\"\"\n",
    "        try:\n",
    "            # Define periods (in days) for views data analysis\n",
    "            periods = {\n",
    "                '7D': 7,\n",
    "                '28D': 28,\n",
    "                '90D': 90,\n",
    "                '1Y': 365,  # 1 year\n",
    "                '3Y': 3 * 365,  # 3 years\n",
    "                'ALL': (datetime.now() - pd.to_datetime(videos_df['published_at']).min()).days  # Lifetime\n",
    "            }\n",
    "            \n",
    "            all_views_data = pd.DataFrame()\n",
    "            now = datetime.now()  # Current datetime (timezone-aware if needed)\n",
    "            \n",
    "            for period, days in periods.items():\n",
    "                # Calculate cutoff date for the current period\n",
    "                cutoff = now - timedelta(days=days)\n",
    "                \n",
    "                # Filter videos based on the 'published_at' date for the current period\n",
    "                period_df = videos_df[videos_df['published_at'] >= cutoff].copy()\n",
    "                \n",
    "                if not period_df.empty:\n",
    "                    # Add period column and calculate additional columns\n",
    "                    period_df['period'] = period\n",
    "                    period_df['days_since_published'] = (now - period_df['published_at']).dt.total_seconds() / (24 * 3600)\n",
    "                    period_df['views_per_day'] = period_df['views'] / period_df['days_since_published']\n",
    "                    \n",
    "                    # Rolling average of views (based on a window of 10 days, or fewer if the data is smaller)\n",
    "                    period_df['rolling_avg_views'] = period_df['views'].rolling(window=min(10, len(period_df))).mean()\n",
    "                    \n",
    "                    # Engagement rate: (likes + comments) / views * 100\n",
    "                    period_df['engagement_rate'] = (period_df['likes'] + period_df['comments']) / period_df['views'] * 100\n",
    "                    \n",
    "                    # Concatenate period data to the main DataFrame\n",
    "                    all_views_data = pd.concat([all_views_data, period_df])\n",
    "            \n",
    "            # Sort the final DataFrame by period and publication date\n",
    "            all_views_data = all_views_data.sort_values(['period', 'published_at']).reset_index(drop=True)\n",
    "            \n",
    "            # Final columns to return\n",
    "            final_columns = [\n",
    "                'period',\n",
    "                'published_at',\n",
    "                'title',\n",
    "                'views',\n",
    "                'likes',\n",
    "                'comments',\n",
    "                'views_per_day',\n",
    "                'rolling_avg_views',\n",
    "                'engagement_rate',\n",
    "                'days_since_published',\n",
    "                'duration'\n",
    "            ]\n",
    "            \n",
    "            return all_views_data[final_columns]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating views data: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Channel Analysis Execution </h1>\n",
    "</div>\n",
    "Running analysis for channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAnalytics:\n",
    "    def __init__(self, channel_info: Dict, videos: List[Dict]):\n",
    "        self.channel_info = channel_info\n",
    "        self.videos_df = pd.DataFrame(videos)\n",
    "        self.videos_df['published_at'] = pd.to_datetime(self.videos_df['published_at'])\n",
    "        \n",
    "    def get_channel_overview(self) -> Dict:\n",
    "        \"\"\"Get basic channel information\"\"\"\n",
    "        return {\n",
    "            'channel_name': self.channel_info['snippet']['title'],\n",
    "            'creation_date': self.channel_info['snippet']['publishedAt'],\n",
    "            'subscriber_count': int(self.channel_info['statistics']['subscriberCount']),\n",
    "            'total_views': int(self.channel_info['statistics']['viewCount']),\n",
    "            'total_videos': int(self.channel_info['statistics']['videoCount'])\n",
    "        }\n",
    "    \n",
    "    def get_performance_metrics(self) -> Dict:\n",
    "        \"\"\"Calculate average performance metrics\"\"\"\n",
    "        return {\n",
    "            'avg_views': self.videos_df['views'].mean(),\n",
    "            'avg_likes': self.videos_df['likes'].mean(),\n",
    "            'avg_comments': self.videos_df['comments'].mean(),\n",
    "            'engagement_rate': (\n",
    "                (self.videos_df['likes'] + self.videos_df['comments']).sum() / \n",
    "                self.videos_df['views'].sum() * 100\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def get_upload_patterns(self) -> Dict:\n",
    "        \"\"\"Analyze upload patterns\"\"\"\n",
    "        sorted_dates = self.videos_df['published_at'].sort_values()\n",
    "        time_diffs = sorted_dates.diff().dropna()\n",
    "        \n",
    "        return {\n",
    "            'avg_days_between_uploads': time_diffs.mean().total_seconds() / (24 * 3600),\n",
    "            'avg_video_duration': self.videos_df['duration'].mean() / 60,  # in minutes\n",
    "            'most_common_upload_day': self.videos_df['published_at'].dt.day_name().mode()[0],\n",
    "            'most_common_upload_hour': self.videos_df['published_at'].dt.hour.mode()[0]\n",
    "        }\n",
    "    \n",
    "    def get_recent_performance(self) -> Dict:\n",
    "        \"\"\"Analyze recent video performance\"\"\"\n",
    "        sorted_df = self.videos_df.sort_values('published_at', ascending=False)\n",
    "        \n",
    "        return {\n",
    "            'avg_views_last_10': sorted_df.head(10)['views'].mean(),\n",
    "            'avg_views_last_30': sorted_df.head(30)['views'].mean(),\n",
    "            'overall_avg_views': sorted_df['views'].mean(),\n",
    "            'trend': (\n",
    "                'Improving' if sorted_df.head(10)['views'].mean() > sorted_df['views'].mean()\n",
    "                else 'Declining'\n",
    "            )\n",
    "        }\n",
    "    \n",
    "    def get_complete_analytics(self) -> Dict:\n",
    "        \"\"\"Get all analytics in one dictionary\"\"\"\n",
    "        return {\n",
    "            'channel_overview': self.get_channel_overview(),\n",
    "            'performance_metrics': self.get_performance_metrics(),\n",
    "            'upload_patterns': self.get_upload_patterns(),\n",
    "            'recent_performance': self.get_recent_performance()\n",
    "        }\n",
    "\n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate a formatted text report of all analytics\"\"\"\n",
    "        analytics = self.get_complete_analytics()\n",
    "        \n",
    "        report = [\n",
    "            \"=== YouTube Channel Analytics Report ===\\n\",\n",
    "            \"\\n== Channel Overview ==\",\n",
    "            f\"Channel Name: {analytics['channel_overview']['channel_name']}\",\n",
    "            f\"Creation Date: {analytics['channel_overview']['creation_date']}\",\n",
    "            f\"Subscriber Count: {analytics['channel_overview']['subscriber_count']:,}\",\n",
    "            f\"Total Views: {analytics['channel_overview']['total_views']:,}\",\n",
    "            f\"Total Videos: {analytics['channel_overview']['total_videos']:,}\",\n",
    "            \n",
    "            \"\\n== Performance Metrics ==\",\n",
    "            f\"Average Views per Video: {analytics['performance_metrics']['avg_views']:,.0f}\",\n",
    "            f\"Average Likes per Video: {analytics['performance_metrics']['avg_likes']:,.0f}\",\n",
    "            f\"Average Comments per Video: {analytics['performance_metrics']['avg_comments']:,.0f}\",\n",
    "            f\"Engagement Rate: {analytics['performance_metrics']['engagement_rate']:.2f}%\",\n",
    "            \n",
    "            \"\\n== Upload Patterns ==\",\n",
    "            f\"Average Days Between Uploads: {analytics['upload_patterns']['avg_days_between_uploads']:.1f}\",\n",
    "            f\"Average Video Duration: {analytics['upload_patterns']['avg_video_duration']:.1f} minutes\",\n",
    "            f\"Most Common Upload Day: {analytics['upload_patterns']['most_common_upload_day']}\",\n",
    "            f\"Most Common Upload Hour: {analytics['upload_patterns']['most_common_upload_hour']:02d}:00\",\n",
    "            \n",
    "            \"\\n== Recent Performance ==\",\n",
    "            f\"Average Views (Last 10): {analytics['recent_performance']['avg_views_last_10']:,.0f}\",\n",
    "            f\"Average Views (Last 30): {analytics['recent_performance']['avg_views_last_30']:,.0f}\",\n",
    "            f\"Overall Average Views: {analytics['recent_performance']['overall_avg_views']:,.0f}\",\n",
    "            f\"Trend: {analytics['recent_performance']['trend']}\"\n",
    "        ]\n",
    "        \n",
    "        return \"\\n\".join(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Generated Data Files </h1>\n",
    "</div>\n",
    "\n",
    "Two comprehensive CSV files are created:\n",
    "1. views_trends_all_periods.csv\n",
    "   - Period-wise view counts\n",
    "   - Engagement metrics\n",
    "   - Performance indicators\n",
    "   \n",
    "2. subscriber_trends_all_periods.csv\n",
    "   - Daily subscriber counts\n",
    "   - Growth rates\n",
    "   - Period-wise trends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Analysis Execution </h1>\n",
    "</div>\n",
    "\n",
    "Running comprehensive analysis for the specified channel:\n",
    "- Data collection and processing\n",
    "- CSV file generation\n",
    "- Visualization creation\n",
    "- Report generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching channel ID: timed out\n",
      "Could not fetch channel data\n"
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "channel_url = \"https://www.youtube.com/@arsalancba\"  # Example channel URL\n",
    "channel_info, videos = get_channel_data(channel_url)\n",
    "\n",
    "if channel_info and videos:\n",
    "    # Create visualizer\n",
    "    viz = YouTubeVisualizer()\n",
    "    channel_id = yt.get_channel_id(channel_url)\n",
    "    \n",
    "    # Process video dates\n",
    "    videos_df = pd.DataFrame(videos)\n",
    "    videos_df['published_at'] = pd.to_datetime(videos_df['published_at']).dt.tz_localize(None)\n",
    "    \n",
    "    # Generate and save views data\n",
    "    views_data = viz.generate_views_data(videos_df)\n",
    "    if views_data is not None:\n",
    "        views_filename = 'analytics_output/views_trends_all_periods.csv'\n",
    "        views_data.to_csv(views_filename, index=False)\n",
    "        print(f\"\\nSaved all views data to {views_filename}\")\n",
    "        \n",
    "    # Generate and save subscriber data\n",
    "    subscriber_data = viz.generate_subscriber_data(channel_id)\n",
    "    if subscriber_data is not None:\n",
    "        subs_filename = 'analytics_output/subscriber_trends_all_periods.csv'\n",
    "        subscriber_data.to_csv(subs_filename, index=False)\n",
    "        print(f\"\\nSaved all subscriber data to {subs_filename}\")\n",
    "    \n",
    "    # Generate and show visualizations\n",
    "    views_graphs, subscriber_graphs = viz.get_all_trend_graphs(videos, channel_id)\n",
    "    \n",
    "    # Display views graphs\n",
    "    for time_range, graph in views_graphs.items():\n",
    "        print(f\"Displaying views trend graph for {time_range}...\")\n",
    "        graph.show()\n",
    "    \n",
    "    # Display subscriber graphs\n",
    "    for time_range, graph in subscriber_graphs.items():\n",
    "        print(f\"Displaying subscriber trend graph for {time_range}...\")\n",
    "        graph.show()\n",
    "else:\n",
    "    print(\"Could not fetch channel data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"border-radius: 30px 0 30px 0; border: 2px solid #00ea98; padding: 20px; background-color: #0a141b; text-align: center; box-shadow: 0px 2px 4px rgba(0, 0, 0, 0.2);\">\n",
    "    <h1 style=\"color: #7ab052; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5); font-weight: bold; margin-bottom: 10px; font-size: 36px;\">Analysis Results </h1>\n",
    "</div>\n",
    "The analysis generates:\n",
    "1. Channel Overview\n",
    "   - Basic channel statistics\n",
    "   - Performance metrics\n",
    "   - Upload patterns\n",
    "\n",
    "2. Trend Analysis\n",
    "   - Views trends for different periods (7D, 28D, 90D, MAX)\n",
    "   - Subscriber growth patterns\n",
    "   - Engagement metrics over time\n",
    "\n",
    "3. Data Files\n",
    "   - views_trends_all_periods.csv: Comprehensive view data\n",
    "   - subscriber_trends_all_periods.csv: Subscriber growth data\n",
    "\n",
    "4. Visualizations\n",
    "   - Views trend graphs\n",
    "   - Upload schedule heatmap\n",
    "   - Engagement analysis\n",
    "   - Subscriber growth visualization\n",
    "\n",
    "All output files are saved in the analytics_output directory for further analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
